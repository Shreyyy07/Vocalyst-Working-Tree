<div align="center">

# ğŸ™ï¸ Vocalyst

### AI-Powered Communication Coaching Platform

*Elevate your public speaking and presentation skills through intelligent multimodal analysis*

[![GitHub Stars](https://img.shields.io/github/stars/Shreyyy07/Vocalyst-Main?style=social)](https://github.com/Shreyyy07/Vocalyst-Main)
[![GitHub Forks](https://img.shields.io/github/forks/Shreyyy07/Vocalyst-Main?style=social)](https://github.com/Shreyyy07/Vocalyst-Main/fork)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Docker Deployment](#-docker-deployment) â€¢ [Technologies](#-technologies-used) â€¢ [Roadmap](#-roadmap)

</div>

---

## ğŸ“– About Vocalyst

**Vocalyst** is an advanced AI-driven communication coaching platform that revolutionizes how individuals improve their public speaking and presentation skills. Unlike traditional tools that focus solely on text analysis, Vocalyst provides comprehensive, real-time multimodal feedback by analyzing:

- ğŸ—£ï¸ **Voice Analysis** - Speech fluency, pacing, tone, and delivery
- ğŸ˜Š **Facial Expressions** - Emotional engagement and confidence levels
- ğŸ‘ï¸ **Eye Contact** - Gaze tracking and audience engagement
- ğŸ“ **Content Structure** - Logical coherence, vocabulary, and engagement

Communication is more than just wordsâ€”it's about how you sound, how you look, and how you structure your message. Vocalyst bridges the gap left by conventional tools by offering a unified, intelligent solution for holistic communication improvement.

---

## âœ¨ Features

### ğŸ¯ Core Capabilities

#### **1. Multimodal Practice Sessions**
- **Real-time Feedback** during presentations
- **Multiple Practice Modes**: General, Persuasive, Emotive, Debate, Storytelling
- **Camera & Audio Integration** for comprehensive analysis
- **Live Metrics Display** with instant feedback

#### **2. Advanced Speech Analysis**
- **Speech Transcription** using OpenAI Whisper
- **Filler Word Detection** (um, uh, like, etc.) with frequency tracking
- **Words Per Minute (WPM)** measurement
- **Clarity Scoring** based on pronunciation and enunciation
- **Vocabulary Sophistication** tracking

#### **3. Visual & Emotional Intelligence**
- **Eye Contact Tracking** via MediaPipe
- **Facial Expression Analysis** using DeepFace
- **Emotion Detection** (neutral, happy, sad, angry, fear, surprise)
- **Engagement Estimation** through facial cues
- **Real-time Visual Feedback** during sessions

#### **4. AI-Powered Insights**
- **Dynamic Session Insights** generated by Google Gemini AI
- **Personalized Recommendations** based on performance
- **Trend Analysis** (improving/declining/stable metrics)
- **Strengths & Weaknesses** identification
- **Gamification** with level/XP system

#### **5. Comprehensive Analytics**
- **Performance Dashboard** with historical trends
- **Session History** with detailed breakdowns
- **Progress Tracking** over time
- **Practice Mode Analytics** with distribution charts
- **Emotional Expression Patterns**
- **Reset Functionality** with data archiving

#### **6. Text-to-Speech Integration**
- **Multiple Voice Options** (8 high-quality AI voices)
- **Speed Control** for customized playback
- **ElevenLabs & Neuphonic** integration
- **Practice Prompts** generation

---

## ğŸš€ Quick Start

### Prerequisites

- **Docker & Docker Compose** (recommended) OR
- **Node.js** (v18+) and **Python** (v3.11+)

### Option 1: Docker Deployment (Recommended)

1. **Clone the repository**
   ```bash
   git clone https://github.com/Shreyyy07/Vocalyst-Main.git
   cd Vocalyst-Main
   ```

2. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

3. **Start with Docker Compose**
   ```bash
   docker-compose up
   ```

4. **Access the application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:5328

### Option 2: Local Development

1. **Clone and install dependencies**
   ```bash
   git clone https://github.com/Shreyyy07/Vocalyst-Main.git
   cd Vocalyst-Main
   
   # Install Python dependencies
   pip install -r requirements.txt
   
   # Install Node.js dependencies
   npm install
   ```

2. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Add your API keys to .env
   ```

3. **Run both servers**
   ```bash
   npm run dev
   ```

   Or run separately:
   ```bash
   # Terminal 1 - Frontend
   npm run next-dev
   
   # Terminal 2 - Backend
   npm run flask-dev
   ```

---

## ğŸ³ Docker Deployment

### Architecture

Vocalyst uses a multi-container Docker setup:
- **Frontend Container**: Next.js production build (Port 3000)
- **Backend Container**: Flask API with ML models (Port 5328)
- **Shared Network**: Bridge network for inter-container communication
- **Persistent Volumes**: Session data and uploads

### Configuration

### Docker Commands

```bash
# Build containers
docker-compose build

# Start services
docker-compose up

# Start in detached mode
docker-compose up -d

# Stop services
docker-compose down

# View logs
docker-compose logs -f

# Rebuild and restart
docker-compose down && docker-compose build && docker-compose up
```

### Data Persistence

- **Session Data**: `./api/data` - Stores practice session analytics
- **Uploads**: `./api/uploads` - Stores recordings and emotion data
- **Archives**: `./api/data/archive` - Archived session data after reset

---

## ğŸ’» Usage

### Starting a Practice Session

1. **Navigate to Practice**
   - Click "Practice" in the navigation menu
   - Select a practice mode (General, Persuasive, Emotive, etc.)

2. **Record Your Presentation**
   - Allow camera and microphone permissions
   - Click "Start Recording"
   - Speak naturally while the system analyzes

3. **Receive Real-time Feedback**
   - Monitor live WPM, clarity, and filler word metrics
   - View eye contact and emotion tracking
   - Get instant visual feedback

4. **Review Detailed Analysis**
   - View comprehensive post-session breakdown
   - Get AI-generated personalized insights
   - See scores for fluency, coherence, and engagement
   - Receive actionable recommendations

### Analytics & Insights

**Analytics Dashboard** (`/analytics`):
- View aggregated performance metrics
- Track practice mode distribution
- Monitor emotional expression patterns
- Review recent session history
- Reset analytics with data archiving

**AI-Powered Insights** (`/get-insights`):
- Gamified progress tracking (Level/XP system)
- Skill breakdown radar chart
- Dynamic strengths and weaknesses
- Performance trends (improving/declining/stable)
- Personalized recommendations
- Reset progress functionality

---

## ğŸ› ï¸ Technologies Used

### Frontend Stack

| Technology | Purpose |
|------------|---------|
| **Next.js 14** | React framework with SSR and production optimization |
| **React 18** | UI component library with hooks |
| **TypeScript** | Type-safe JavaScript development |
| **Tailwind CSS** | Utility-first styling framework |
| **Framer Motion** | Smooth animations and transitions |
| **Recharts** | Data visualization and charts |
| **Lucide React** | Modern icon library |

### Backend Stack

| Technology | Purpose |
|------------|---------|
| **Flask** | Python web framework for API |
| **Flask-CORS** | Cross-origin resource sharing |
| **Google Gemini AI** | Dynamic insights generation |
| **Neuphonic** | Enhanced TTS and speech processing |
| **ElevenLabs** | High-quality text-to-speech |

### AI/ML Models

| Model | Purpose | Performance |
|-------|---------|-------------|
| **OpenAI Whisper** | Speech-to-text transcription | State-of-the-art accuracy |
| **RoBERTa (large)** | Logical coherence detection | High performance |
| **XGBoost** | Speech fluency classification | 93% F1 Score |
| **Google Gemini Pro** | AI insights generation | Real-time analysis |

### Audio Processing

- **Librosa** - Audio feature extraction (MFCC, ZCR, energy)
- **Neuphonic** - Enhanced speech signal processing
- **OpenAI Whisper** - Accurate speech transcription
- **SoundDevice** - Real-time audio capture

### Computer Vision

- **MediaPipe** - Face landmark detection (68 points)
- **OpenCV** - Video processing and frame analysis
- **DeepFace** - Facial expression and emotion recognition
- **GazeTracking** - Eye contact estimation

### Deployment

- **Docker** - Containerization platform
- **Docker Compose** - Multi-container orchestration
- **Gunicorn** - Production WSGI server
- **Next.js Production Build** - Optimized frontend

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VOCALYST PLATFORM (Docker)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Frontend      â”‚       â”‚    Backend     â”‚
            â”‚  Container      â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚   Container    â”‚
            â”‚  (Next.js)      â”‚  REST â”‚   (Flask)      â”‚
            â”‚  Port: 3000     â”‚  API  â”‚  Port: 5328    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                         â”‚                         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  SPEECH MODULE  â”‚       â”‚  VISUAL MODULE â”‚       â”‚   AI INSIGHTS  â”‚
            â”‚   (Whisper)     â”‚       â”‚  (MediaPipe)   â”‚       â”‚   (Gemini)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                         â”‚                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                     â”‚   â”‚                   â”‚    â”‚                   â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚Filler   â”‚          â”‚  WPM    â”‚            â”‚DeepFace â”‚            â”‚Dynamic  â”‚
    â”‚Detectionâ”‚          â”‚Tracking â”‚            â”‚Emotions â”‚            â”‚Insights â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   ANALYTICS DASHBOARD   â”‚
                    â”‚  - Session History      â”‚
                    â”‚  - Trends & Progress    â”‚
                    â”‚  - Recommendations      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
Vocalyst-Main/
â”œâ”€â”€ api/                          # Backend Flask API
â”‚   â”œâ”€â”€ index.py                  # Main API endpoints
â”‚   â”œâ”€â”€ simple_tts.py            # TTS subprocess handler
â”‚   â”œâ”€â”€ tonality.py              # Tonality analysis
â”‚   â”œâ”€â”€ data/                    # Session data storage
â”‚   â”‚   â”œâ”€â”€ sessions.json        # Practice sessions
â”‚   â”‚   â””â”€â”€ archive/             # Archived data
â”‚   â”œâ”€â”€ uploads/                 # User recordings
â”‚   â”œâ”€â”€ Dockerfile               # Backend container config
â”‚   â””â”€â”€ requirements.txt         # Python dependencies
â”‚
â”œâ”€â”€ app/                         # Next.js frontend
â”‚   â”œâ”€â”€ analytics/               # Analytics dashboard
â”‚   â”œâ”€â”€ get-insights/           # AI insights page
â”‚   â”œâ”€â”€ practice/               # Practice session interface
â”‚   â”œâ”€â”€ camera/                 # Camera capture
â”‚   â”œâ”€â”€ tts/                    # Text-to-speech lab
â”‚   â”œâ”€â”€ Dockerfile              # Frontend container config
â”‚   â””â”€â”€ page.tsx                # Landing page
â”‚
â”œâ”€â”€ components/                  # Reusable React components
â”‚   â””â”€â”€ ui/                     # UI component library
â”‚
â”œâ”€â”€ docker-compose.yml          # Multi-container orchestration
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ .dockerignore              # Docker ignore rules
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ package.json              # Node.js dependencies
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                # This file
```

---

## ğŸ¯ Key Features Breakdown

### Session Analysis
- **Real-time Metrics**: Live WPM, clarity, filler word tracking
- **Post-Session Breakdown**: Comprehensive analysis with scores
- **AI Insights**: Unique, personalized feedback per session
- **Historical Tracking**: Progress monitoring over time

### Analytics Dashboard
- **Aggregated Metrics**: Average WPM, filler %, clarity, duration
- **Practice Mode Distribution**: Visual breakdown by category
- **Emotional Patterns**: Emotion distribution across sessions
- **Recent Sessions**: Quick access to session history
- **Reset Functionality**: Archive and clear data

### AI-Powered Insights
- **Dynamic Analysis**: Real-time strengths/weaknesses calculation
- **Trend Detection**: Improving/declining/stable metrics
- **Personalized Recommendations**: Actionable improvement tips
- **Gamification**: Level/XP system for motivation
- **Skill Visualization**: Radar chart for skill breakdown

---

## ğŸ—ºï¸ Roadmap

### âœ… Completed Features
- [x] Docker containerization and deployment
- [x] Dynamic AI insights with Gemini API
- [x] Analytics reset with data archiving
- [x] Enhanced insights page with gamification
- [x] Skill breakdown radar chart
- [x] Performance trend analysis
- [x] Multi-voice TTS integration

### ğŸš€ Upcoming Features
- [ ] **Multilingual Support** - 20+ languages for global accessibility
- [ ] **Mobile Application** - iOS and Android native apps
- [ ] **Real-Time Coaching** - Live suggestions during presentations
- [ ] **Team Collaboration** - Multi-user sessions and peer feedback
- [ ] **Custom Training Modules** - Industry-specific templates
- [ ] **Integration APIs** - Zoom, Teams, Meet connectivity
- [ ] **Advanced Emotion AI** - Context-aware sentiment analysis
- [ ] **Voice Cloning** - Personalized TTS with user's voice
- [ ] **Presentation Templates** - Pre-built scenarios and scripts
- [ ] **Export Reports** - PDF/PowerPoint presentation reports

---

## ğŸ” Security & Privacy

- **Local Processing**: All ML models run locally in Docker containers
- **No Data Sharing**: Session data stays on your machine
- **Environment Variables**: Secure API key management
- **Data Archiving**: Safe reset with backup functionality
- **CORS Protection**: Configured cross-origin policies

---

## ğŸ¤ Contributing

We welcome contributions! Here's how:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 for Python, ESLint for TypeScript
- Write meaningful commit messages
- Add comments for complex logic
- Update documentation as needed

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Author

- **Shreyyy07** - [GitHub Profile](https://github.com/Shreyyy07)

---

<div align="center">

**â­ Star this repository if you find it helpful!**

**ğŸ› Found a bug?** [Open an issue](https://github.com/Shreyyy07/Vocalyst-Main/issues)

**ğŸ’¡ Have a feature idea?** [Start a discussion](https://github.com/Shreyyy07/Vocalyst-Main/discussions)

Made with â¤ï¸ by Shreyyy07

</div>
